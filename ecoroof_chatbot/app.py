import streamlit as st
from openai import OpenAI
from dotenv import load_dotenv
import os

# Charger les variables d'environnement
load_dotenv()
api_key = os.getenv("api_key")

# Cr√©er le client OpenAI
client = OpenAI(api_key = api_key)

st.title("üîÜüö≤ Expert Photovolta√Øque & Pistes Cyclables")

st.markdown("""
Pose une question √† un expert sp√©cialis√© en :
- √ânergie photovolta√Øque (panneaux bifaciaux, ombri√®res solaires)
- Pistes cyclables et voies vertes en France

_Exemples_ :
- "Quels sont les avantages des panneaux bifaciaux ?"
- "Comment int√©grer des pistes cyclables dans un projet rural ?"
""")

user_prompt = st.text_input("Tu es un expert en production d'√©nergie photovolta√Øque pour les panneaux bifaciaux ET en ombri√®res ET sur le sujet des pistes cyclables ET l'am√®nagement des voies vertes en France. "
        "R√©ponds de mani√®re claire, factuelle et adapt√©e au contexte fran√ßais.")

if user_prompt:
    with st.spinner("R√©ponse en cours..."):
        response = client.chat.completions.create(
            model="gpt-4o",  # ou gpt-4o-mini
            messages=[
                {"role": "system", "content": (
                    "Tu es un expert en √©nergie photovolta√Øque (notamment les panneaux bifaciaux, les ombri√®res solaires), "
                    "ainsi qu'en am√©nagement des pistes cyclables et voies vertes en France. "
                    "Tu donnes des r√©ponses factuelles, pr√©cises, claires et contextualis√©es pour la France."
                )},
                {"role": "user", "content": user_prompt}
            ]
        )

        answer = response.choices[0].message.content
        st.success("R√©ponse de l'expert :")
        st.markdown(answer)